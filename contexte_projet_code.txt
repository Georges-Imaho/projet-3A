### STRUCTURE COMPL√àTE DU PROJET ###
projet_sauvetage/
    requirements.txt
    .gitignore
    main.py
    code_to_text.py
    notebook/
        Data_Load.ipynb
        test_LSTM.ipynb
        BlackScholes.ipynb
    data/
        train_data.csv
        test_data.csv
    src/
        deep_hedger.py
        hedging_engine.py
        analytics_models.py
        market_simulator.py

==================================================

#### CONTENU DU FICHIER : main.py ####
def bite ():
#### FIN DU FICHIER : main.py ####

#### CONTENU DU FICHIER : code_to_text.py ####
import os
import json
import nbformat

# --- Configuration ---
# Dossiers et fichiers syst√®me √† ignorer
IGNORE_LIST = {
    '.git', '__pycache__', 'venv', '.venv', 'node_modules', 
    '.ipynb_checkpoints', '.DS_Store', 'contexte_projet.txt', 
    'contexte_projet_notebooks.txt', 'contexte_projet_code.txt', # On s'ignore soi-m√™me pour √©viter une boucle
    '.idea', '.vscode'
}

OUTPUT_FILE = "contexte_projet_code.txt"

def extract_notebook_content(filepath):
    """
    Lit un fichier .ipynb avec nbformat et extrait uniquement 
    les cellules de type CODE et MARKDOWN.
    """
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            nb = nbformat.read(f, as_version=4)
            content = []
            for i, cell in enumerate(nb.cells):
                cell_type = cell.cell_type.upper()
                source = cell.source
                content.append(f"--- Cellule {i} [{cell_type}] ---\n{source}\n")
            return "\n".join(content)
    except Exception as e:
        return f"[Erreur lors de la lecture du Notebook : {e}]\n"

def extract_py_content(filepath):
    """
    Lit simplement le contenu textuel d'un fichier .py
    """
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        return f"[Erreur lors de la lecture du fichier Python : {e}]\n"

def generate_context_file(root_dir, output_file):
    with open(output_file, 'w', encoding='utf-8') as f_out:
        
        # --- 1. G√âN√âRATION DE L'ARBORESCENCE COMPL√àTE ---
        f_out.write("### STRUCTURE COMPL√àTE DU PROJET ###\n")
        
        for root, dirs, files in os.walk(root_dir):
            dirs[:] = [d for d in dirs if d not in IGNORE_LIST]
            
            level = root.replace(root_dir, '').count(os.sep)
            indent = ' ' * 4 * level
            
            f_out.write(f"{indent}{os.path.basename(root)}/\n")
            
            sub_indent = ' ' * 4 * (level + 1)
            for f in files:
                if f not in IGNORE_LIST:
                    f_out.write(f"{sub_indent}{f}\n")
        
        f_out.write("\n" + "="*50 + "\n\n")

        # --- 2. EXTRACTION DU CONTENU (.ipynb ET .py) ---
        for root, dirs, files in os.walk(root_dir):
            dirs[:] = [d for d in dirs if d not in IGNORE_LIST]
            
            for file in files:
                full_path = os.path.join(root, file)
                relative_path = os.path.relpath(full_path, root_dir)
                
                # Gestion des Notebooks
                if file.endswith('.ipynb'):
                    f_out.write(f"#### CONTENU DU FICHIER : {relative_path} ####\n")
                    f_out.write(extract_notebook_content(full_path))
                    f_out.write(f"\n#### FIN DU FICHIER : {relative_path} ####\n\n")
                
                # Gestion des fichiers Python standards
                elif file.endswith('.py'):
                    f_out.write(f"#### CONTENU DU FICHIER : {relative_path} ####\n")
                    f_out.write(extract_py_content(full_path))
                    f_out.write(f"\n#### FIN DU FICHIER : {relative_path} ####\n\n")

if __name__ == "__main__":
    chemin_actuel = os.getcwd()
    print(f"Analyse du projet dans : {chemin_actuel}")
    print(f"1. G√©n√©ration de l'arborescence compl√®te.")
    print(f"2. Extraction du code des fichiers .ipynb et .py.")
    
    generate_context_file(chemin_actuel, OUTPUT_FILE)
    
    print(f"Termin√© ! Le fichier '{OUTPUT_FILE}' a √©t√© g√©n√©r√©.")
#### FIN DU FICHIER : code_to_text.py ####

#### CONTENU DU FICHIER : notebook/Data_Load.ipynb ####
--- Cellule 0 [CODE] ---
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import sys

# --- 1. CONFIGURATION DU CHEMIN ---
# Le notebook est dans "notebook/", les modules dans "src/"
# On ajoute le dossier racine (..) au path pour pouvoir faire "from src..."
project_root = os.path.abspath('..')
if project_root not in sys.path:
    sys.path.append(project_root)

# --- 2. CR√âATION DU DOSSIER DATA ---
DATA_DIR = os.path.join(project_root, "data")
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)
    print(f"üìÇ Dossier cr√©√© : {DATA_DIR}")
else:
    print(f"üìÇ Dossier donn√©es d√©tect√© : {DATA_DIR}")

# --- 3. IMPORTS DES MODULES DU PROJET ---
try:
    # Attention : v√©rifie si ton fichier s'appelle market_simulator.py ou market_simulators.py
    # D'apr√®s ton arborescence, c'est le singulier : market_simulator
    from src.market_simulator import MarketSimulator
    from src.analytics_models import BlackScholesOracle
    print("‚úÖ Imports des modules src r√©ussis !")
except ImportError as e:
    print(f"‚ùå Erreur d'import : {e}")
    print("V√©rifie que les fichiers .py sont bien dans le dossier '../src/'")

# Config graphique
sns.set_theme(style="whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)

--- Cellule 1 [CODE] ---
# --- TEST VISUEL : SIMULATEUR DE MARCH√â (GBM) ---

# Param√®tres
S0 = 100       # Prix initial
T = 1.0        # 1 an
N_STEPS = 252  # Jours de bourse
N_PATHS = 10   # Nombre de courbes √† afficher

# Instanciation
sim = MarketSimulator(s0=S0, r=0.05, sigma=0.2)

# G√©n√©ration
paths = sim.simulate_gbm(steps=N_STEPS, n_paths=N_PATHS)

# Visualisation
plt.figure(figsize=(10, 6))
plt.plot(paths)
plt.title(f"Simulation de {N_PATHS} trajectoires (Mouvement Brownien G√©om√©trique)")
plt.xlabel("Jours de trading")
plt.ylabel("Prix ($)")
plt.axhline(y=S0, color='black', linestyle='--', label="Prix Initial")
plt.legend()
plt.show()

--- Cellule 2 [CODE] ---
# --- G√âN√âRATION DU DATASET (100 000 SC√âNARIOS) ---

N_SAMPLES = 100000
print(f"üöÄ G√©n√©ration de {N_SAMPLES} options...")

np.random.seed(42) # Reproductibilit√©

# 1. Inputs al√©atoires (X)
S = np.random.uniform(50, 150, N_SAMPLES)      # Spot Price
K = np.random.uniform(50, 150, N_SAMPLES)      # Strike Price
T = np.random.uniform(0.1, 2.0, N_SAMPLES)     # Maturit√© (ann√©es)
r = np.random.uniform(0.01, 0.05, N_SAMPLES)   # Taux (1% - 5%)
sigma = np.random.uniform(0.1, 0.5, N_SAMPLES) # Volatilit√© (10% - 50%)

# 2. Calcul du Label (Y) avec l'Oracle que tu viens de coder
# On calcule le prix du CALL
calls = BlackScholesOracle.get_price(S, K, T, r, sigma, option_type='call')

# 3. Cr√©ation du DataFrame
df = pd.DataFrame({
    'S': S, 'K': K, 'T': T, 'r': r, 'sigma': sigma,
    'call_price': calls
})

# Feature Engineering simple (utile pour l'analyse)
df['moneyness'] = df['S'] / df['K']

print("Aper√ßu des donn√©es g√©n√©r√©es :")
display(df.head())

--- Cellule 3 [CODE] ---
# --- SAUVEGARDE (TRAIN / TEST SPLIT) ---

# M√©lange des donn√©es
df = df.sample(frac=1, random_state=42).reset_index(drop=True)

# S√©paration 80% / 20%
split_idx = int(0.8 * len(df))
train_df = df.iloc[:split_idx]
test_df = df.iloc[split_idx:]

# Chemins de sauvegarde
train_path = os.path.join(DATA_DIR, "train_data.csv")
test_path = os.path.join(DATA_DIR, "test_data.csv")

train_df.to_csv(train_path, index=False)
test_df.to_csv(test_path, index=False)

print(f"‚úÖ Fichiers sauvegard√©s avec succ√®s !")
print(f"   Train : {train_path} ({len(train_df)} lignes)")
print(f"   Test  : {test_path} ({len(test_df)} lignes)")

--- Cellule 4 [CODE] ---
# --- ANALYSE DES DONN√âES G√âN√âR√âES ---

fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# 1. Relation Prix Spot vs Prix Option
# On prend un √©chantillon al√©atoire de 2000 points pour ne pas surcharger le graph
sample = df.sample(2000) 
sns.scatterplot(
    data=sample, x='S', y='call_price', 
    hue='moneyness', palette='viridis', ax=axes[0]
)
axes[0].set_title("Prix Call vs Spot (Color√© par Moneyness)")
axes[0].set_xlabel("Spot Price ($)")
axes[0].set_ylabel("Call Price ($)")

# 2. Distribution des prix
sns.histplot(df['call_price'], bins=50, ax=axes[1], color='purple', kde=True)
axes[1].set_title("Distribution des Prix des Calls")
axes[1].set_xlabel("Prix du Call")

plt.tight_layout()
plt.show()

--- Cellule 5 [CODE] ---


#### FIN DU FICHIER : notebook/Data_Load.ipynb ####

#### CONTENU DU FICHIER : notebook/test_LSTM.ipynb ####
[Erreur lors de la lecture du Notebook : Notebook does not appear to be JSON: '']

#### FIN DU FICHIER : notebook/test_LSTM.ipynb ####

#### CONTENU DU FICHIER : notebook/BlackScholes.ipynb ####
--- Cellule 0 [MARKDOWN] ---
# Black Scholes

--- Cellule 1 [CODE] ---
import numpy as np
from scipy.stats import norm
import matplotlib.pyplot as plt

--- Cellule 2 [CODE] ---
def black_scholes_call(S, K, T, r, sigma):
    # 1. Calculate d1
    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))
    
    # 2. Calculate d2
    d2 = d1 - sigma * np.sqrt(T)
    
    # 3. Apply the formula: C = S*N(d1) - K*exp(-rT)*N(d2)
    C = (S * norm.cdf(d1)) - (K * np.exp(-r * T) * norm.cdf(d2))
    
    return C

# Example usage:
spot = 100      # S
strike = 105    # K
time = 1        # T (1 year)
rate = 0.05     # r (5%)
vol = 0.2       # sigma (20%)

price = black_scholes_call(spot, strike, time, rate, vol)
print(f"The fair price of the Call Option (C) is: {price:.2f}")

--- Cellule 3 [CODE] ---
def simulate_stock_path(S0, T, r, sigma, steps):
    dt = T / steps
    # Generate random movements (Brownian Motion increments)
    W = np.random.standard_normal(steps) 
    W = np.cumsum(W) * np.sqrt(dt) # Cumulative sum to get the path
    
    time_steps = np.linspace(0, T, steps)
    # The Black-Scholes dynamic formula
    S_path = S0 * np.exp((r - 0.5 * sigma**2) * time_steps + sigma * W)
    
    return time_steps, S_path

# Visualizing 5 possible futures for the stock
plt.figure(figsize=(10, 6))
for i in range(5):
    t, path = simulate_stock_path(100, 1, 0.05, 0.2, 252)
    plt.plot(t, path)

plt.axhline(y=105, color='r', linestyle='--', label='Strike Price (K)')
plt.title("Simulated Stock Price Paths (S) vs Strike (K)")
plt.xlabel("Time (Years)")
plt.ylabel("Stock Price")
plt.legend()
plt.show()

#### FIN DU FICHIER : notebook/BlackScholes.ipynb ####

#### CONTENU DU FICHIER : src/deep_hedger.py ####
import torch
import torch.nn as nn

class DeepHedgingModel(nn.Module):
    def __init__(self, input_dim=3, hidden_dim=32, output_dim=1):
        super(DeepHedgingModel, self).__init__()
        self.hidden_dim = hidden_dim
        
        # On ajoute +1 √† l'input_dim pour inclure le "Previous Delta"
        self.lstm_cell = nn.LSTMCell(input_size=input_dim + 1, hidden_size=hidden_dim)
        
        self.decision_layer = nn.Sequential(
            nn.Linear(hidden_dim, 32),
            nn.ReLU(),
            nn.Linear(32, output_dim),
            nn.Sigmoid() 
        )

    def forward(self, x, initial_position=None):
        """
        x shape: [Batch, Time, Features]
        """
        batch_size, seq_len, _ = x.size()
        
        # Initialisation des √©tats cach√©s (h_t, c_t)
        h_t = torch.zeros(batch_size, self.hidden_dim, device=x.device)
        c_t = torch.zeros(batch_size, self.hidden_dim, device=x.device)
        
        # Position initiale (0 actions au d√©but)
        if initial_position is None:
            prev_delta = torch.zeros(batch_size, 1, device=x.device)
        else:
            prev_delta = initial_position

        deltas = []
        
        # --- BOUCLE TEMPORELLE (On avance jour apr√®s jour) ---
        for t in range(seq_len):
            # 1. On r√©cup√®re les features du march√© du jour t
            market_features = x[:, t, :] # [Batch, Features]
            
            # 2. On concat√®ne avec la position de la veille (L'IA sait ce qu'elle a en poche)
            combined_input = torch.cat([market_features, prev_delta], dim=1) 
            
            # 3. Update de la m√©moire LSTM
            h_t, c_t = self.lstm_cell(combined_input, (h_t, c_t))
            
            # 4. D√©cision d'action
            current_delta = self.decision_layer(h_t)
            
            # 5. On sauvegarde pour la boucle suivante et pour la sortie
            prev_delta = current_delta
            deltas.append(current_delta)
            
        # On recolle tout sous forme [Batch, Time, 1]
        return torch.stack(deltas, dim=1)

# --- Test rapide pour v√©rifier que les dimensions collent ---
if __name__ == "__main__":
    # Simulation d'un batch de donn√©es
    batch_size = 64
    seq_len = 30     # 30 jours
    n_features = 3   # (Log-Price, Time-to-Maturity, Volatility)
    
    # Cr√©ation du mod√®le
    model = DeepHedgingModel(input_dim=n_features)
    
    # Cr√©ation d'une entr√©e al√©atoire (Dummy data)
    dummy_input = torch.randn(batch_size, seq_len, n_features)
    
    # Passage dans le mod√®le
    output = model(dummy_input)
    
    print(f"Input shape  : {dummy_input.shape}") # [64, 30, 3]
    print(f"Output shape : {output.shape}")      # [64, 30, 1]
    print("‚úÖ Le mod√®le fonctionne techniquement (les dimensions sont correctes).")
#### FIN DU FICHIER : src/deep_hedger.py ####

#### CONTENU DU FICHIER : src/hedging_engine.py ####
import torch
import torch.nn as nn
import numpy as np

class HedgingEngine:
    """
    Le Gymnase : G√®re la simulation, le calcul du PnL (Profits & Pertes) 
    et l'apprentissage du mod√®le avec prise en compte des frictions.
    """
    def __init__(self, model, optimizer, criterion, transaction_cost_pct=0.0, risk_aversion=1.0):
        """
        Args:
            model: Le r√©seau de neurones (DeepHedger)
            optimizer: L'optimiseur (Adam)
            criterion: La fonction de perte de base (souvent MSE)
            transaction_cost_pct (float): Co√ªts de transaction (ex: 0.001 pour 0.1%)
        """
        self.model = model
        self.optimizer = optimizer
        self.criterion = criterion
        self.cost_pct = transaction_cost_pct
        self.risk_aversion = risk_aversion

    def _compute_pnl(self, spot_paths, strikes, deltas, T):
        """
        Calcule le PnL (Profit and Loss) final de la strat√©gie de couverture.
        C'est le calcul financier pur.
        """
        # 1. Calcul des variations de prix (dS) : S(t+1) - S(t)
        # spot_paths shape: [Batch, Time]
        price_changes = torch.diff(spot_paths, dim=1) 
        
        # 2. Alignement des deltas
        # On utilise le delta d√©cid√© en t pour profiter du mouvement entre t et t+1
        # On coupe le dernier delta car il ne sert √† rien √† la maturit√©
        active_deltas = deltas[:, :-1, 0] 
        
        # 3. Profit g√©n√©r√© par la strat√©gie de hedging (Gain sur actions)
        # Somme (Quantit√© d√©tenue * Variation de prix)
        hedging_pnl = torch.sum(active_deltas * price_changes, dim=1)
        
        # 4. Calcul des co√ªts de transaction
        # Co√ªt = |Delta_t - Delta_{t-1}| * Prix_t * Taux_Frais
        # On ajoute une colonne de z√©ros au d√©but pour le premier achat
        zeros = torch.zeros((deltas.shape[0], 1, 1), device=deltas.device)
        padded_deltas = torch.cat([zeros, deltas], dim=1)
        
        # Changement de position
        delta_changes = torch.abs(torch.diff(padded_deltas, dim=1))
        
        # On simplifie en appliquant les frais sur le prix moyen ou spot instantan√©
        # Ici on applique sur le spot path align√©
        costs = torch.sum(delta_changes[:, :-1, 0] * spot_paths[:, :-1] * self.cost_pct, dim=1)
        
        # 5. Payoff de l'option (Ce qu'on doit payer au client √† la fin)
        # Payoff Call = Max(S_T - K, 0)
        final_prices = spot_paths[:, -1]
        option_payoff = torch.relu(final_prices - strikes)
        
        # 6. PnL Total = Premium (vendu au d√©but) + Hedging PnL - Costs - Payoff (pay√© √† la fin)
        # Note : Pour l'entra√Ænement, on cherche juste √† minimiser la variance entre 
        # (Hedging - Costs) et (Payoff). On ignore souvent le Premium car c'est une constante.
        
        return hedging_pnl - costs - option_payoff

    def train_step(self, spot_paths, strikes, inputs):
        self.model.train()
        self.optimizer.zero_grad()
        
        deltas = self.model(inputs)
        pnl = self._compute_pnl(spot_paths, strikes, deltas, T=1.0)
        
        # --- CORRECTION : NORMALISATION ---
        # On divise le PnL par le Strike (K) pour travailler en %
        # Exemple : PnL de 1$ sur Strike 100$ = 1%
        normalized_pnl = pnl / strikes
        
        # On booste l'importance du Profit dans la Loss
        # On veut que l'IA soit "gourmande"
        risk = torch.var(normalized_pnl)
        reward = torch.mean(normalized_pnl)
        
        # On force le ratio : on veut autant minimiser le risque que maximiser le profit
        # Le facteur 1.0 ou 2.0 ici est crucial.
        loss = risk - (self.risk_aversion * reward)
        
        loss.backward()
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
        self.optimizer.step()
        
        return loss.item(), reward.item() # On renvoie le reward brut pour l'affichage

# --- Test rapide de la logique de calcul ---
if __name__ == "__main__":
    # Simulation de donn√©es factices
    batch_sz = 5
    seq_len = 10
    
    # Prix qui montent de 100 √† 110
    spots = torch.linspace(100, 110, seq_len).repeat(batch_sz, 1)
    strikes = torch.full((batch_sz,), 100.0)
    
    # Deltas factices (Le mod√®le ach√®te 0.5 action et garde)
    deltas = torch.full((batch_sz, seq_len, 1), 0.5)
    
    # Instance Engine (sans mod√®le pour tester juste la m√©thode statique PnL)
    engine = HedgingEngine(None, None, None, transaction_cost_pct=0.01)
    
    # Calcul PnL
    pnl = engine._compute_pnl(spots, strikes, deltas, T=1.0)
    
    print(f"PnL Batch shape : {pnl.shape}")
    print(f"PnL Moyen : {pnl.mean().item():.2f}")
    print("‚úÖ Le moteur de calcul financier fonctionne.")
#### FIN DU FICHIER : src/hedging_engine.py ####

#### CONTENU DU FICHIER : src/analytics_models.py ####
import numpy as np
from scipy.stats import norm

class BlackScholesOracle:
    """
    L'Oracle : Impl√©mente la formule ferm√©e de Black-Scholes pour le pricing.
    Supporte la vectorisation (entr√©es sous forme de tableaux NumPy).
    """
    
    @staticmethod
    def get_price(S, K, T, r, sigma, option_type='call'):
        """
        Calcule le prix d'une option europ√©enne.
        
        Args:
            S (float or array): Prix actuel du sous-jacent (Spot)
            K (float or array): Prix d'exercice (Strike)
            T (float or array): Temps restant jusqu'√† maturit√© (en ann√©es)
            r (float or array): Taux d'int√©r√™t sans risque
            sigma (float or array): Volatilit√© du sous-jacent
            option_type (str): 'call' ou 'put'
            
        Returns:
            float or array: Prix de l'option
        """
        # Pour √©viter la division par z√©ro si T=0
        T = np.maximum(T, 1e-8)
        
        # Calcul de d1 et d2
        d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))
        d2 = d1 - sigma * np.sqrt(T)
        
        if option_type.lower() == 'call':
            price = S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)
        elif option_type.lower() == 'put':
            price = K * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1)
        else:
            raise ValueError("option_type doit √™tre 'call' ou 'put'")
            
        return price

    @staticmethod
    def get_delta(S, K, T, r, sigma, option_type='call'):
        """
        Calcule le Delta de l'option (utile pour la comparaison en Semaine 3).
        Delta = dV/dS (sensibilit√© du prix de l'option au prix du sous-jacent).
        """
        T = np.maximum(T, 1e-8)
        d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))
        
        if option_type.lower() == 'call':
            return norm.cdf(d1)
        else:
            return norm.cdf(d1) - 1

# --- Petit script de test ---
if __name__ == "__main__":
    # Test unitaire
    S, K, T, r, sigma = 100, 100, 1, 0.05, 0.2
    
    call_price = BlackScholesOracle.get_price(S, K, T, r, sigma, 'call')
    put_price = BlackScholesOracle.get_price(S, K, T, r, sigma, 'put')
    delta_call = BlackScholesOracle.get_delta(S, K, T, r, sigma, 'call')
    
    print(f"Test pour S=100, K=100, T=1an, r=5%, sigma=20%:")
    print(f"  - Prix du Call : {call_price:.4f}")
    print(f"  - Prix du Put  : {put_price:.4f}")
    print(f"  - Delta du Call: {delta_call:.4f}")

    # Test de vectorisation (calculer 3 prix d'un coup)
    S_vec = np.array([90, 100, 110])
    prices = BlackScholesOracle.get_price(S_vec, K, T, r, sigma)
    print(f"\nTest vectorisation (3 prix) : {prices}")
#### FIN DU FICHIER : src/analytics_models.py ####

#### CONTENU DU FICHIER : src/market_simulator.py ####
import numpy as np

class MarketSimulator:
    """
    Simulateur de prix d'actifs financiers.
    """
    def __init__(self, s0, r, sigma, dt=1/252):
        self.s0 = s0          # Prix initial de l'action
        self.r = r            # Taux sans risque (ex: 0.03 pour 3%)
        self.sigma = sigma    # Volatilit√© (ex: 0.2 pour 20%)
        self.dt = dt          # Pas de temps (1/252 = 1 jour de bourse)

    def simulate_gbm(self, steps, n_paths=1):
        """
        G√©n√®re des trajectoires via le Mouvement Brownien G√©om√©trique (GBM).
        Formule : dS_t = r*S_t*dt + sigma*S_t*dW_t
        """
        # G√©n√©ration des chocs al√©atoires normaux (dW_t)
        # Taille : (Nombre de pas, Nombre de trajectoires)
        z = np.random.standard_normal((steps, n_paths))
        
        # Calcul de la d√©rive et de la diffusion
        # On utilise la forme exponentielle : S_t = S_0 * exp((r - 0.5*sigma^2)*t + sigma*W_t)
        drift = (self.r - 0.5 * self.sigma**2) * self.dt
        diffusion = self.sigma * np.sqrt(self.dt) * z
        
        # Calcul des rendements logarithmiques cumul√©s
        log_returns = drift + diffusion
        cum_log_returns = np.cumsum(log_returns, axis=0)
        
        # Ajout du prix initial (log(S0)) et passage √† l'exponentielle
        paths = self.s0 * np.exp(np.vstack([np.zeros(n_paths), cum_log_returns]))
        
        return paths
    
    def simulate_heston(self, steps, n_paths=1, kappa=2.0, theta=0.2, xi=0.3, rho=-0.7):
        """
        Simule le mod√®le de Heston (Volatilit√© Stochastique).
        
        Args:
            kappa (float): Vitesse de retour √† la moyenne de la volatilit√©.
            theta (float): Volatilit√© moyenne √† long terme.
            xi (float): "Volatilit√© de la volatilit√©" (nervosit√© du march√©).
            rho (float): Corr√©lation entre le prix et la volatilit√© (Souvent n√©gative : quand le prix chute, la peur monte).
        
        Returns:
            paths (ndarray): Prix de l'actif [steps+1, n_paths]
            vol_paths (ndarray): Volatilit√© instantan√©e [steps+1, n_paths]
        """
        # 1. G√©n√©ration des chocs al√©atoires corr√©l√©s
        # Z1 pour le prix, Z2 pour la volatilit√©
        z1 = np.random.standard_normal((steps, n_paths))
        z2_uncorrelated = np.random.standard_normal((steps, n_paths))
        # Corr√©lation des browniens : W2 = rho*W1 + sqrt(1-rho^2)*Z2
        z2 = rho * z1 + np.sqrt(1 - rho**2) * z2_uncorrelated

        # 2. Initialisation des tableaux
        # On a besoin de stocker la volatilit√© √† chaque instant
        price_paths = np.zeros((steps + 1, n_paths))
        vol_paths = np.zeros((steps + 1, n_paths))
        
        # Conditions initiales
        price_paths[0] = self.s0
        vol_paths[0] = theta # On commence √† la moyenne long terme (ex: 20%)

        dt = self.dt
        sqrt_dt = np.sqrt(dt)

        # 3. Boucle temporelle (Euler-Maruyama)
        # On ne peut pas tout vectoriser d'un coup car t d√©pend de t-1
        for t in range(steps):
            S_t = price_paths[t]
            v_t = vol_paths[t]
            
            # S'assurer que la variance reste positive (Absorbtion ou R√©flexion)
            v_t = np.maximum(v_t, 1e-5) # S√©curit√© num√©rique
            sqrt_vt = np.sqrt(v_t)

            # Mise √† jour de la Volatilit√© (Processus CIR)
            # dv = kappa * (theta - v) * dt + xi * sqrt(v) * dW_vol
            d_vol = kappa * (theta - v_t) * dt + xi * sqrt_vt * z2[t] * sqrt_dt
            vol_paths[t+1] = v_t + d_vol
            
            # Mise √† jour du Prix
            # dS = r * S * dt + sqrt(v) * S * dW_price
            d_price = self.r * S_t * dt + sqrt_vt * S_t * z1[t] * sqrt_dt
            price_paths[t+1] = S_t + d_price

        # On retourne les prix ET les volatilit√©s (car le LSTM aura besoin de voir la vol)
        return price_paths, np.sqrt(np.maximum(vol_paths, 1e-5))

# Exemple d'utilisation rapide pour tester :
if __name__ == "__main__":
    sim = MarketSimulator(s0=100, r=0.05, sigma=0.2)
    # Simuler 10 trajectoires sur 252 jours (1 an)
    trajectoires = sim.simulate_gbm(steps=252, n_paths=10)
    print(f"Forme de la matrice de sortie : {trajectoires.shape}") # (253, 10)
    print(f"Prix finaux des 5 premi√®res trajectoires : {trajectoires[-1, :5]}")
#### FIN DU FICHIER : src/market_simulator.py ####

